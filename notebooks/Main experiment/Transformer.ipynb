{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.35.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame.from_records(json.load(open('../../data/train.json'))).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Concatenate 'title' and 'abstract'\n",
    "train['combined_text'] = train['title'] + ' ' + train['abstract']\n",
    "\n",
    "# Step 2: Obtain sentence embeddings for the combined text\n",
    "embeddings = model.encode(train['combined_text'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
      "0  0.003490 -0.002893 -0.029641  0.013807  0.045661  0.004433 -0.015949   \n",
      "1  0.049272  0.025005 -0.034317  0.025440 -0.073576 -0.046910 -0.012463   \n",
      "2 -0.003629 -0.010785 -0.028453  0.048054 -0.069712  0.032118  0.012705   \n",
      "3  0.005922  0.056695 -0.019930 -0.030621  0.010721  0.030278  0.004040   \n",
      "4  0.021016  0.015016 -0.034241 -0.005293 -0.017108  0.015270 -0.017285   \n",
      "\n",
      "      dim_8     dim_9    dim_10  ...   dim_760   dim_761   dim_762   dim_763  \\\n",
      "0  0.037939 -0.051580  0.009515  ...  0.007225  0.007118  0.020501 -0.007893   \n",
      "1  0.024625  0.005171 -0.025421  ...  0.004504 -0.008347  0.052653 -0.017780   \n",
      "2 -0.016930 -0.063091 -0.042111  ...  0.049551 -0.026112 -0.009532 -0.016229   \n",
      "3 -0.011463 -0.042495 -0.043800  ...  0.064271  0.031771  0.043024  0.003078   \n",
      "4  0.026525  0.002404  0.010120  ... -0.013973  0.002729  0.015522 -0.043427   \n",
      "\n",
      "    dim_764   dim_765   dim_766   dim_767   dim_768  year  \n",
      "0 -0.018392  0.020200 -0.043240  0.032976  0.035801  2009  \n",
      "1 -0.028084  0.057998  0.011713 -0.030564 -0.037949  1991  \n",
      "2 -0.021461 -0.010622 -0.007442 -0.002590  0.025402  2008  \n",
      "3 -0.042332 -0.012012 -0.004662 -0.078200 -0.059156  2016  \n",
      "4  0.024818  0.053882  0.004350 -0.072213 -0.000428  2014  \n",
      "\n",
      "[5 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create a new DataFrame with the sentence embeddings and 'year' as the target variable\n",
    "embedding_columns = [f'dim_{i+1}' for i in range(embeddings.shape[1])]\n",
    "embedding_df = pd.DataFrame(embeddings.numpy(), columns=embedding_columns)\n",
    "embedding_df.reset_index(drop=True, inplace=True)\n",
    "result_df = pd.concat([embedding_df, pd.to_numeric(train['year'])], axis=1)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor mae 6.679513449341964\n",
      "Ridge Regressor mae 4.629345174220314\n",
      "Linear Regressor mae 4.636169807678996\n"
     ]
    }
   ],
   "source": [
    "def train_model(df, m, name):\n",
    "    model = m\n",
    "    train, val = train_test_split(df, stratify=df['year'], random_state=123)\n",
    "    model.fit(train.drop('year', axis=1), train['year'].values)\n",
    "    predictions = model.predict(val.drop('year', axis=1))\n",
    "    mae = mean_absolute_error(val['year'].values, predictions)\n",
    "    print(\"{0} mae {1}\".format(name,mae))\n",
    "\n",
    "train_model(result_df, DecisionTreeRegressor(),\"Decision Tree Regressor\")\n",
    "train_model(result_df, Ridge(),\"Ridge Regressor\")\n",
    "train_model(result_df, LinearRegression(),\"Linear Regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kNN(df, neighbors, metrics):\n",
    "    scores = {}\n",
    "\n",
    "    for k in neighbors:\n",
    "        scores[k] = {}\n",
    "        for metric in metrics:\n",
    "            model = KNeighborsRegressor(n_neighbors=k, metric=metric, weights= 'distance')\n",
    "            train, val = train_test_split(df, stratify=df['year'], random_state=123)\n",
    "            model.fit(train.drop('year', axis=1), train['year'].values)\n",
    "            predictions = model.predict(val.drop('year', axis=1))\n",
    "            mae = mean_absolute_error(val['year'].values, predictions)\n",
    "            print(f\"{k}-Nearest Neighbors with similarity function '{metric}': MAE = {mae}\")\n",
    "            scores[k][metric] = mae\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Nearest Neighbors with similarity function 'cosine': MAE = 4.440439347047758\n",
      "1-Nearest Neighbors with similarity function 'euclidean': MAE = 4.438861581406648\n",
      "2-Nearest Neighbors with similarity function 'cosine': MAE = 4.084740521070501\n",
      "2-Nearest Neighbors with similarity function 'euclidean': MAE = 4.105121968543005\n",
      "3-Nearest Neighbors with similarity function 'cosine': MAE = 3.9630431662974814\n",
      "3-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9930708711016334\n",
      "4-Nearest Neighbors with similarity function 'cosine': MAE = 3.90969339213855\n",
      "4-Nearest Neighbors with similarity function 'euclidean': MAE = 3.943579259090733\n",
      "5-Nearest Neighbors with similarity function 'cosine': MAE = 3.8879529107377016\n",
      "5-Nearest Neighbors with similarity function 'euclidean': MAE = 3.926777902846579\n",
      "6-Nearest Neighbors with similarity function 'cosine': MAE = 3.874491800990524\n",
      "6-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9163323159954015\n",
      "7-Nearest Neighbors with similarity function 'cosine': MAE = 3.8670177019226966\n",
      "7-Nearest Neighbors with similarity function 'euclidean': MAE = 3.909925692394376\n",
      "8-Nearest Neighbors with similarity function 'cosine': MAE = 3.8618125699952848\n",
      "8-Nearest Neighbors with similarity function 'euclidean': MAE = 3.907554487021411\n",
      "9-Nearest Neighbors with similarity function 'cosine': MAE = 3.8717850027267007\n",
      "9-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9201752832313868\n",
      "10-Nearest Neighbors with similarity function 'cosine': MAE = 3.8703007509108955\n",
      "10-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9190687453515256\n",
      "11-Nearest Neighbors with similarity function 'cosine': MAE = 3.874147441523173\n",
      "11-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9233427342722256\n",
      "12-Nearest Neighbors with similarity function 'cosine': MAE = 3.873523809636109\n",
      "12-Nearest Neighbors with similarity function 'euclidean': MAE = 3.9227350785040342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {'cosine': 4.440439347047758, 'euclidean': 4.438861581406648},\n",
       " 2: {'cosine': 4.084740521070501, 'euclidean': 4.105121968543005},\n",
       " 3: {'cosine': 3.9630431662974814, 'euclidean': 3.9930708711016334},\n",
       " 4: {'cosine': 3.90969339213855, 'euclidean': 3.943579259090733},\n",
       " 5: {'cosine': 3.8879529107377016, 'euclidean': 3.926777902846579},\n",
       " 6: {'cosine': 3.874491800990524, 'euclidean': 3.9163323159954015},\n",
       " 7: {'cosine': 3.8670177019226966, 'euclidean': 3.909925692394376},\n",
       " 8: {'cosine': 3.8618125699952848, 'euclidean': 3.907554487021411},\n",
       " 9: {'cosine': 3.8717850027267007, 'euclidean': 3.9201752832313868},\n",
       " 10: {'cosine': 3.8703007509108955, 'euclidean': 3.9190687453515256},\n",
       " 11: {'cosine': 3.874147441523173, 'euclidean': 3.9233427342722256},\n",
       " 12: {'cosine': 3.873523809636109, 'euclidean': 3.9227350785040342}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = np.arange(1, 13, 1)\n",
    "metrics = ['cosine', 'euclidean']\n",
    "\n",
    "train_kNN(result_df, neighbors, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_records(json.load(open('../../data/test.json'))).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def main():\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    logging.info(\"Loading train/test data\")\n",
    "\n",
    "    train = pd.DataFrame.from_records(json.load(open('../../data/train.json'))).fillna(\"\")\n",
    "    test = pd.DataFrame.from_records(json.load(open('../../data/test.json'))).fillna(\"\")\n",
    "\n",
    "    full_set = pd.concat([train, test])\n",
    "\n",
    "    # Step 1: Concatenate 'title' and 'abstract'\n",
    "    logging.info(\"Combining title and abstract columns\")\n",
    "    full_set['combined_text'] = full_set['title'] + ' ' + full_set['abstract']\n",
    "\n",
    "    # Step 2: Obtain sentence embeddings for the combined text\n",
    "    logging.info(\"Loading SentenceTransformer all-mpnet-base-v2 model\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    logging.info(\"Extract 768 dimensional sentence embeddings for train/test data\")\n",
    "    embeddings = model.encode(full_set['combined_text'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "    # Step 3: Create a new DataFrame with the sentence embeddings and 'year' as the target variable\n",
    "    logging.info(\"Convert vectors to train dataframe\")\n",
    "    embedding_columns = [f'dim_{i+1}' for i in range(embeddings.shape[1])]\n",
    "    embedding_df = pd.DataFrame(embeddings.numpy(), columns=embedding_columns)\n",
    "\n",
    "    x = len(train)\n",
    "    train_df = embedding_df.iloc[:x, :]\n",
    "    test_df = embedding_df.iloc[x:, :]\n",
    "\n",
    "    # Step 4: Get nearest neighbors\n",
    "    logging.info(\"Predict years\")\n",
    "    kNN = KNeighborsRegressor(n_neighbors=8, metric='cosine', weights= 'distance')\n",
    "    kNN.fit(train_df, pd.to_numeric(train['year'].values))\n",
    "    pred = kNN.predict(test_df)\n",
    "    test['year'] = pred\n",
    "    logging.info(\"Writing prediction file\")\n",
    "    test.to_json(\"predicted.json\", orient='records', indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading train/test data\n",
      "INFO:root:Combining title and abstract columns\n",
      "INFO:root:Loading SentenceTransformer all-mpnet-base-v2 model\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035c28dfeff440a8b35ac9837f0861c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85277bd8897a4fd08d4ee5b916660a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2504aa934dae41629256fd16600900e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462c258b1b7a47229368b2b2553133e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae010cd67e647c9a9f6c5c1845257cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6733300a3045409cf6394af9aaa00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14b4f8408c14ec8bb7bd072528373a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a941dbeb4d64bc592ba91094fc9ae49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291ea8212b124f6ea9a7e50b4c92b753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2482ef5852d44f5cb1fbb888a0f46bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4002fed799714516b603fbd1502be4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fe41fcf2204912aa68b481fa5f719e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3819c98987ba42aba32b0028b2ddff8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63dd1f028f33471e98c72f279d2a4eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "INFO:root:Extract 768 dimensional sentence embeddings for train/test data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522e739c443a4b839a47cd80f8e899c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Convert vectors to train dataframe\n",
      "INFO:root:Predict years\n",
      "INFO:root:Writing prediction file\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
